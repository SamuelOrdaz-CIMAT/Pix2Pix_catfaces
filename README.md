# Pix2Pix: GeneraciÃ³n de Rostros de Gatos desde Landmarks

ImplementaciÃ³n de **Pix2Pix** (Conditional GAN) para generar imÃ¡genes realistas de rostros de gatos a partir de mapas de calor de landmarks faciales. El proyecto utiliza el dataset **CatFLW** y arquitecturas U-Net + PatchGAN para lograr una traducciÃ³n imagen-a-imagen de alta calidad.

## ğŸ¯ Objetivo

Transformar representaciones abstractas de landmarks faciales (9 puntos clave: ojos, nariz, boca, orejas) en imÃ¡genes fotorrealistas de gatos mediante aprendizaje adversarial condicional.

## ğŸ—ï¸ Arquitectura

### Generador: U-Net
- **Encoder**: 7 capas de downsampling (64 â†’ 512 canales)
- **Bottleneck**: Capa de 512 canales en resoluciÃ³n 2Ã—2
- **Decoder**: 7 capas de upsampling con skip connections
- **Dropout**: 50% en las primeras 3 capas del decoder
- **Salida**: Tanh activation para normalizaciÃ³n [-1, 1]

### Discriminador: PatchGAN
- Clasificador de parches 30Ã—30 para detalles locales
- 5 capas convolucionales (64 â†’ 512 canales)
- BatchNorm excepto en primera capa
- Salida sin sigmoid (usa BCEWithLogitsLoss)

## ğŸ“Š Dataset: CatFLW

- **Total**: 2,090 imÃ¡genes de rostros de gatos
- **Split**: 80% train / 10% val / 10% test
- **ResoluciÃ³n**: 256Ã—256 pÃ­xeles
- **Landmarks**: 9 puntos faciales clave
- **Preprocesamiento**: 
  - Mapas de calor Gaussianos (Ïƒ=2 para definiciÃ³n Ã³ptima)
  - Recorte por bounding box
  - NormalizaciÃ³n [-1, 1]

## ğŸ”§ ConfiguraciÃ³n de Entrenamiento

### ParÃ¡metros Optimizados (Ã‰poca 200)
```python
epochs = 200
batch_size = 32
lambda_L1 = 60          # PÃ©rdida de reconstrucciÃ³n L1
lambda_perc = 3         # PÃ©rdida perceptual VGG16
sigma = 3               # DesviaciÃ³n estÃ¡ndar Gaussiana
learning_rate = 2e-4
betas = (0.5, 0.999)
```

### Funciones de PÃ©rdida
1. **Adversarial Loss**: BCEWithLogitsLoss con label smoothing
   - Real labels: 0.9 + ruido [0, 0.1]
   - Fake labels: ruido [0, 0.1]
2. **L1 Loss**: ReconstrucciÃ³n pixel-a-pixel (Î»=60)
3. **Perceptual Loss**: Features VGG16 (layers [:16], Î»=3)

### TÃ©cnicas de OptimizaciÃ³n
- **AMP (Automatic Mixed Precision)**: FP16 para 2Ã— speedup
- **LambdaLR Scheduler**: Decaimiento lineal desde Ã©poca 100
- **Data Augmentation**: 
  - HorizontalFlip (50%)
  - ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05)

## ğŸ“ˆ Resultados (Ã‰poca 200)

| MÃ©trica | Valor | Objetivo |
|---------|-------|----------|
| **Loss D** | 0.473 | 0.3-0.7 âœ… |
| **Loss G** | 29.88 | 20-30 âœ… |
| **Val L1** | 0.488 | <0.15 âš ï¸ |
| **PSNR** | ~4.37 dB | >20 dB âŒ |
| **SSIM** | N/A | >0.70 âŒ |

### Estado Actual
- âœ… **Equilibrio adversarial perfecto** (D y G estables)
- âœ… **Estructura facial correcta** (ojos, nariz, boca bien posicionados)
- âš ï¸ **Blur en detalles finos** (bigotes, textura de pelaje, definiciÃ³n de ojos)

### Causa del Blur
El valor alto de `lambda_L1=60` fuerza al generador a priorizar reconstrucciÃ³n promedio sobre detalles de alta frecuencia, resultando en sobre-suavizado.

## ğŸš€ Uso

### InstalaciÃ³n
```bash
pip install torch torchvision opencv-python numpy pillow tqdm matplotlib piq
```

### Preparar Dataset
```python
prepare_catflw_dataset(
    input_root="CatFLW dataset",
    output_root="datasets/catflw",
    sigma=3
)
```

### Entrenar Modelo
```python
G = train_pix2pix(
    dataset_root="datasets/catflw",
    epochs=200,
    batch_size=32,
    lambda_L1=60,
    lambda_perc=3
)
```

### Evaluar en Test
```python
evaluate_on_test(G, dataset_root="datasets/catflw/test")
show_samples(G, test_loader, device, n=5)
```

### Reanudar Entrenamiento
El sistema detecta automÃ¡ticamente `checkpoints/last_checkpoint.pth` y continÃºa desde la Ãºltima Ã©poca guardada.

## ğŸ“ Estructura del Proyecto

```
pix2pix/
â”œâ”€â”€ pix2pix_proyect.ipynb      # Notebook principal
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ .gitignore                  # Exclusiones de Git
â”œâ”€â”€ CatFLW dataset/            # Dataset original (no versionado)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ datasets/                   # Dataset procesado (no versionado)
â”‚   â””â”€â”€ catflw/
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ val/
â”‚       â””â”€â”€ test/
â”œâ”€â”€ checkpoints/               # Modelos guardados
â”‚   â”œâ”€â”€ G_best.pth            # Mejor generador (versionado)
â”‚   â”œâ”€â”€ D_best.pth            # Mejor discriminador (versionado)
â”‚   â”œâ”€â”€ last_checkpoint.pth   # Estado completo (no versionado)
â”‚   â””â”€â”€ G_epoch{N}.pth        # Checkpoints periÃ³dicos (no versionados)
â””â”€â”€ results/                   # Salidas del entrenamiento
    â”œâ”€â”€ training_log.csv      # MÃ©tricas por Ã©poca (versionado)
    â”œâ”€â”€ epoch_{N}.png         # Visualizaciones (no versionadas)
    â””â”€â”€ samples.png           # Resultados finales (no versionados)
```

## ğŸ”„ PrÃ³ximos Pasos: OptimizaciÃ³n Anti-Blur

### Estrategia Propuesta
1. **Reducir lambda_L1**: 60 â†’ 40 (-33%)
2. **Reducir lambda_perc**: 3 â†’ 1.5 (-50%)
3. **Sharper sigma**: 3 â†’ 2 (landmarks mÃ¡s definidos)
4. **Enhanced augmentation**: RotaciÃ³n, affine, ColorJitter agresivo
5. **Extender epochs**: 200 â†’ 250

### Expectativas
- **PSNR**: 22-26 dB
- **SSIM**: 0.75-0.85
- **Detalles visibles**: Bigotes individuales, textura de pelaje, ojos nÃ­tidos

## ğŸ“ Historial de Versiones

### Ã‰poca 200 (Actual)
- Entrenamiento base completado
- Lambda ajustado en Ã©poca 101 (100/5 â†’ 60/3)
- Generador converge correctamente
- **Pending**: Resolver blur en detalles finos

## ğŸ› ï¸ TecnologÃ­as

- **PyTorch 2.x**: Framework de deep learning
- **CUDA**: AceleraciÃ³n GPU
- **torchvision**: Transformaciones y VGG16 preentrenado
- **OpenCV**: Procesamiento de imÃ¡genes
- **piq**: MÃ©tricas SSIM
- **tqdm**: Barras de progreso

## ğŸ‘¨â€ğŸ’» Autor

**Samuel Ordaz**  
ğŸ“§ samuel.ordaz@cimat.mx

## ğŸ“„ Licencia

Este proyecto es parte de investigaciÃ³n acadÃ©mica en Deep Learning.

## ğŸ™ Referencias

- Isola, P., et al. (2017). "Image-to-Image Translation with Conditional Adversarial Networks" (Pix2Pix paper)
- Ronneberger, O., et al. (2015). "U-Net: Convolutional Networks for Biomedical Image Segmentation"
- Dataset CatFLW: Facial Landmarks in the Wild for Cats
